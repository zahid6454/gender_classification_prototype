# -*- coding: utf-8 -*-
"""Gender_Classification_LSTM_Model_Builder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aePeqDukNEbdhFpu_BvLvgDxxThCU3V-
"""

from google.colab import drive
drive.mount('/content/drive')

# Python Pckages
import random
import string
import pandas as pd
import numpy as np
from tabulate import tabulate
import matplotlib.pyplot as plt

# ML Packages
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# ML Classifiers
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier

# Deep ML Packages
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, Dense, Activation, Dropout, LSTM, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from tensorflow.keras.utils import plot_model
import tensorflow as tf
from tensorflow import keras

# ML Metrics
from sklearn.metrics import accuracy_score

gpu = tf.test.gpu_device_name()
gpu

removing_characters = list(string.punctuation+'0123456789'+'\t'+'\n')
def data_preprocessing(df):
  # Removing NaN Data
  df = df.dropna()

  # Seperating Male Indices and Female Indices
  male_df = []
  female_df = []
  for i in range(df.shape[0]):
    if df.iloc[i, 1] == 'male':
      male_df.append(i)
    elif df.iloc[i, 1] == 'female':
      female_df.append(i)
    df.iloc[i, 0] = str(df.iloc[i, 0]).lower()
    # Removing Special Characters and Digits
    temp = ''
    for char in df.iloc[i, 0]:
      if char not in removing_characters:
        temp += char
    df.iloc[i, 0] = temp
    
  # Creating New Dataset where Number of Male == Number of Female
  sampled_indices = list(random.sample(male_df, len(female_df))) + female_df
  sampled_df = df.iloc[sampled_indices, :]

  for i in range(sampled_df.shape[0]):
    if sampled_df.iloc[i, 1] == "male":
      sampled_df.iloc[i, 1] = "M"
    else:
      sampled_df.iloc[i, 1] = "F"
  
  sampled_df = sampled_df.sample(frac=1)

  return sampled_df

# Extracting Maximum Length of All The Names
def max_length_extractor_names(names):
  max_length = 0
  for name in names:
    if max_length < len(name):
      max_length = len(name)
  return max_length

# Builds an empty line with a 1 at the index of character
def set_flag(i):
    temp = np.zeros(len_vocabulary);
    temp[i] = 1
    return list(temp)

# Truncate names and create the matrix
def prepare_X(X):
    new_list = []
    trunc_train_name = [str(i)[0:maxlen] for i in X]

    for i in trunc_train_name:
        tmp = [set_flag(char_index[j]) for j in str(i)]
        for k in range(0,maxlen - len(str(i))):
            tmp.append(set_flag(char_index["END"]))
        new_list.append(tmp)

    return new_list

# Label Encoding of y
def prepare_y(y):
    new_list = []
    for i in y:
        if i == 'M':
            new_list.append([1,0])
        else:
            new_list.append([0,1])
    return new_list

# Load our data
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Datasets/Train_Dataset.csv")
df.head()

df = data_preprocessing(df)
df.head()

df.shape

customer_names = df['CUSTOMER_NAME'].apply(lambda x: x.lower())
gender = df['GENDER']
plt.figure(figsize=(12,8))
plt.hist([len(name) for name in customer_names], bins=72)
plt.title("Length of Names")
plt.show()

print("Male : " + str(sum(gender=='M')))
print("Female : " + str(sum(gender=='F')))

vocabulary = list(set(' '.join([str(i) for i in customer_names])))
vocabulary.append('END')
len_vocabulary = len(vocabulary)
print(len_vocabulary)
vocabulary.sort()
print(vocabulary)

char_index = dict((c, i) for i, c in enumerate(vocabulary))
char_index

maxlen = max_length_extractor_names(customer_names)
labels = len(list(set(gender)))
print(f"Maximum Name Length: {maxlen} \t Labels: {labels}")

X = []
y = []
print(customer_names.values[0])
X = prepare_X(customer_names.values)
y = prepare_y(gender)

for i in range(len(X[0])):
  print(X[0][i])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

model = Sequential()
model.add(Bidirectional(LSTM(512, return_sequences=True), 
                        backward_layer=LSTM(512, return_sequences=True, go_backwards=True), 
                        input_shape=(maxlen,len_vocabulary)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(512)))
model.add(Dropout(0.2))
model.add(Dense(2, activity_regularizer=l2(0.002)))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])

plot_model(model, to_file='/content/drive/MyDrive/Colab Notebooks/Models/Model.png', show_shapes=True, expand_nested=True)

callback = EarlyStopping(monitor='val_loss', patience=5)
mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Models/Model.h5', monitor='val_loss', mode='min', verbose=1)
reduce_lr_acc = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=2, verbose=1, min_delta=1e-4, mode='max')

batch_size = 256
history = model.fit(X_train, y_train, batch_size=batch_size, epochs=35, 
                    verbose=1, validation_data =(X_test, y_test), 
                    callbacks=[callback, mc, reduce_lr_acc])

plt.figure(figsize=(12,8))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.figure(figsize=(12,8))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

test_names = ["Rayhan Rashid",
              "Rani",
              "Afsana Yeasmin Mili",
              "Rayhana",
              "Md. Zahid Hossain Khan", 
              "Shahriar Haque", 
              "Ashique Jubayer",
              "Nowsin", 
              "Shajedul Islam",
              "Saif Ahmed Anik", 
              "Toriqul Islam",
              "Afrina Yeasmin Mithila",
              "MD. Khalid Hossain Khan",
              "Md. Faruque Hossain Khan",
              "Md. Abdul Aziz Khan",
              "Samsun Nahar",
              "Farhana Sharmin",
              "Mahbub Azam",
              "Roni Hauladar", 
              "Chowdhuri Mofizur Rahman",
              "Sajid Ahmed",
              "Swakkhar Swatabda",
              "Sabila Nowshin",
              "Rifat Jabin",
              "Tithi",
              "Tanvir Rashid",
              "Kamrul Islam Tushar",
              "Sahanaj",
              "Suma Akhter",
              "Nishat Fariha",
              "Faiza Alam",
              "Ripon Khan",
              "Ridita Afrin"]

for i in range(len(test_names)):
  temp = ''
  for char in test_names[i]:
    if char not in removing_characters:
      temp += char
  test_names[i] = temp
test_names

X_pred = prepare_X([name.lower() for name in test_names])
predictions = model.predict(X_pred)
predictions

test_prediction = ['M' if np.argmax(prediction) == 0 else 'F' for prediction in predictions]

test_table = []
for i in range(len(test_names)):
  test_table.append([test_names[i], test_prediction[i]])
print("\n\n## Test Names Result ##\n")
print(tabulate(test_table, headers= ['Name', 'Gender']))

##### 50K Test Data #####

# Loading Saved Model
model = keras.models.load_model("/content/drive/MyDrive/Colab Notebooks/Models/Model - Run 1.h5")

# Load test data
test_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Datasets/Dataset_0.6_Million.csv")
test_df.head()

print(test_df.shape)
test_df = test_df.dropna()
print(test_df.shape)

with tf.device("/gpu:0"):
  for i in range(test_df.shape[0]):
    temp = ''
    for char in test_df.iloc[i, 0]:
      if char not in removing_characters:
        temp += char
    test_df.iloc[i, 0] = temp
    test_df.iloc[i, 0], test_df.iloc[i, 1] = str(test_df.iloc[i, 0]).lower(), str(test_df.iloc[i, 1]).lower()
    if test_df.iloc[i, 1] == 'male':
      test_df.iloc[i, 1] = 'M'
    else:
      test_df.iloc[i, 1] = 'F'
  test_df.head()

with tf.device("/gpu:0"):
  final_accuracy = []
  final_predictions = []
  final_test_y = []
  final_test_X = []
  hop = 44343
  start = 0
  end = hop
  while end <= test_df.shape[0]:
    test_X, test_y = list(test_df.iloc[start:end, 0]), list(test_df.iloc[start:end, 1])
    test_X_pred = prepare_X(test_X)
    test_predictions = model.predict(test_X_pred)
    final_test_predictions = ['M' if np.argmax(prediction) == 0 else 'F' for prediction in test_predictions]
    final_test_X.append(test_X)
    final_test_y.append(test_y)
    final_predictions.append(final_test_predictions)
    accuracy = accuracy_score(test_y, final_test_predictions)
    final_accuracy.append(accuracy)
    start += hop
    end += hop
    print(f"Accuracy : {round(accuracy * 100, 2)}%")

rX = []
rY = []
rP = []
for i in range(len(final_test_X)):
  for j in range(len(final_test_X[i])):
    rX.append(final_test_X[i][j])
    rY.append(final_test_y[i][j])
    rP.append(final_predictions[i][j])

print(final_accuracy)

print(f"Accuracy : {round(np.mean(final_accuracy) * 100, 2)}%")

result = pd.DataFrame(list(zip(rX, rY, rP)), columns=['Name', 'Original Gender', 'Predicted Gender'])
result.to_csv('/content/drive/MyDrive/Colab Notebooks/Results/Result(LSTM) - 0.6 Million - Run 1.csv', index=False)

# result_16 = result_06 + result_10
# result_16

# print("==> 1 Million Test Data\n")
# for i in range(len(result_10)):
#   print(f"Batch \t{i+1}: {round(result_10[i] * 100, 2)} %")
# print(f"Average\t  : {round(np.mean(result_10) * 100, 2)} %")

# print("\n\n==> 0.6 Million Test Data\n")
# for i in range(len(result_06)):
#   print(f"Batch \t{i+1}: {round(result_06[i] * 100, 2)} %")
# print(f"Average\t  : {round(np.mean(result_06) * 100, 2)} %")

# print(f"Average Accuracy of 1.6 Million Data: {round(np.mean(result_16) * 100, 2)}%")

# test_X_pred = prepare_X(test_X)
# test_predictions = model.predict(test_X_pred)
# test_predictions

# final_test_predictions = ['M' if np.argmax(prediction) == 0 else 'F' for prediction in test_predictions]

# accuracy = accuracy_score(test_y, final_test_predictions)
# print(f"Accuracy : {round(accuracy * 100, 2)}%")

# result = pd.DataFrame(list(zip(test_X, test_y, final_test_predictions)), columns=['Name', 'Original Gender', 'Predicted Gender'])
# result.to_csv('/content/drive/MyDrive/Colab Notebooks/Results/Result(LSTM) - 0.6 Million.csv', index=False)

# Average Accuracy of 0.6 Million Data: 90.97%
# Average Accuracy of 1.0 Million Data: 91.00%
# Average Accuracy of 1.6 Million Data: 90.99%

for i in range(30):
  print(i+1, 998575/(i+1))

